{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNzCugCB80/NwDMw3jMKp3u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamhero2709/Learning-Projects-Notebook/blob/main/tensorflow_withdl/LSTM_for_Language_Modeling_tensorflow6_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RECURRENT NETWORKS and LSTM IN DEEP LEARNING\n",
        "---"
      ],
      "metadata": {
        "id": "lx9pmFOTbMqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "D6QVq9slbNYg"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data\n",
        "!wget -q -O data/ptb.zip https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML241EN-SkillsNetwork/labs/datasets/ptb.zip\n",
        "!unzip -o data/ptb.zip -d data\n",
        "!cp data/ptb/reader.py ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMglmy4Qbd8U",
        "outputId": "9a6a6efd-dd9a-4925-dee8-50f95df9fb4d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  data/ptb.zip\n",
            "   creating: data/ptb/\n",
            "  inflating: data/ptb/reader.py      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import reader"
      ],
      "metadata": {
        "id": "7z9S2dxWbuPC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building The LSTM model for Language Moedling\n",
        "---"
      ],
      "metadata": {
        "id": "b8xPyNMObx9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading and the extracting the simple example dataset\n",
        "!wget http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz\n",
        "!tar xzf simple-examples.tgz -C data/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BgkyQM6b4IZ",
        "outputId": "0284bf69-6315-43b5-e041-3564d708081e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-16 08:57:15--  http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz\n",
            "Resolving www.fit.vutbr.cz (www.fit.vutbr.cz)... 147.229.9.23, 2001:67c:1220:809::93e5:917\n",
            "Connecting to www.fit.vutbr.cz (www.fit.vutbr.cz)|147.229.9.23|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.fit.vut.cz/~imikolov/rnnlm/simple-examples.tgz [following]\n",
            "--2025-07-16 08:57:15--  https://www.fit.vut.cz/~imikolov/rnnlm/simple-examples.tgz\n",
            "Resolving www.fit.vut.cz (www.fit.vut.cz)... 147.229.9.65, 2001:67c:1220:809::93e5:941\n",
            "Connecting to www.fit.vut.cz (www.fit.vut.cz)|147.229.9.65|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.fit.vut.cz/person/imikolov/public/rnnlm/simple-examples.tgz [following]\n",
            "--2025-07-16 08:57:17--  https://www.fit.vut.cz/person/imikolov/public/rnnlm/simple-examples.tgz\n",
            "Reusing existing connection to www.fit.vut.cz:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 34869662 (33M) [application/x-gzip]\n",
            "Saving to: ‘simple-examples.tgz’\n",
            "\n",
            "simple-examples.tgz 100%[===================>]  33.25M  6.06MB/s    in 7.8s    \n",
            "\n",
            "2025-07-16 08:57:25 (4.26 MB/s) - ‘simple-examples.tgz’ saved [34869662/34869662]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Initial weight scale\n",
        "init_scale = 0.1\n",
        "#Initial learning rate\n",
        "learning_rate = 1.0\n",
        "#Maximum permissible norm for the gradient (For gradient clipping -- another measure against Exploding Gradients)\n",
        "max_grad_norm = 5\n",
        "#The number of layers in our model\n",
        "num_layers = 2\n",
        "#The total number of recurrence steps, also known as the number of layers when our RNN is \"unfolded\"\n",
        "num_steps = 20\n",
        "#The number of processing units (neurons) in the hidden layers\n",
        "hidden_size_l1 = 256\n",
        "hidden_size_l2 = 128\n",
        "#The maximum number of epochs trained with the initial learning rate\n",
        "max_epoch_decay_lr = 4\n",
        "#The total number of epochs in training\n",
        "max_epoch = 15\n",
        "#The probability for keeping data in the Dropout Layer (This is an optimization, but is outside our scope for this notebook!)\n",
        "#At 1, we ignore the Dropout Layer wrapping.\n",
        "keep_prob = 1\n",
        "#The decay for the learning rate\n",
        "decay = 0.5\n",
        "#The size for each batch of data\n",
        "batch_size = 30\n",
        "#The size of our vocabulary\n",
        "vocab_size = 10000\n",
        "embeding_vector_size= 200\n",
        "#Training flag to separate training from testing\n",
        "is_training = 1\n",
        "#Data directory for our dataset\n",
        "data_dir = \"data/simple-examples/data/\""
      ],
      "metadata": {
        "id": "l3Q6cvmEc6o9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Initial weight scale\n",
        "init_scale = 0.1\n",
        "#Initial learning rate\n",
        "learning_rate = 1.0\n",
        "#Maximum permissible norm for the gradient (For gradient clipping -- another measure against Exploding Gradients)\n",
        "max_grad_norm = 5\n",
        "#The number of layers in our model\n",
        "num_layers = 2\n",
        "#The total number of recurrence steps, also known as the number of layers when our RNN is \"unfolded\"\n",
        "num_steps = 20\n",
        "#The number of processing units (neurons) in the hidden layers\n",
        "hidden_size_l1 = 256\n",
        "hidden_size_l2 = 128\n",
        "#The maximum number of epochs trained with the initial learning rate\n",
        "max_epoch_decay_lr = 4\n",
        "#The total number of epochs in training\n",
        "max_epoch = 15\n",
        "#The probability for keeping data in the Dropout Layer (This is an optimization, but is outside our scope for this notebook!)\n",
        "#At 1, we ignore the Dropout Layer wrapping.\n",
        "keep_prob = 1\n",
        "#The decay for the learning rate\n",
        "decay = 0.5\n",
        "#The size for each batch of data\n",
        "batch_size = 30\n",
        "#The size of our vocabulary\n",
        "vocab_size = 10000\n",
        "embeding_vector_size= 200\n",
        "#Training flag to separate training from testing\n",
        "is_training = 1\n",
        "#Data directory for our dataset\n",
        "data_dir = \"data/simple-examples/data/\""
      ],
      "metadata": {
        "id": "SxSNBU0LdmV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reads the data and seperated it into training datat m validation datat and testing data\n",
        "raw_data=reader.ptb_raw_datat(data_dir)\n",
        "train_data, valid_data, test_data, vocab, word_to_id = raw_data"
      ],
      "metadata": {
        "id": "E_pxujmndmrF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHDozJmLeA5w",
        "outputId": "d359edea-3ef4-401b-d45e-4ba3713ea923"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "929589"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(valid_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRJ7cJ-LeKaG",
        "outputId": "267a659b-0606-4563-9256-9f271fe0b788"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "73760"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def id_to_word(id_list):\n",
        "    line = []\n",
        "    for w in id_list:\n",
        "        for word, wid in word_to_id.items():\n",
        "            if wid == w:\n",
        "                line.append(word)\n",
        "    return line\n",
        "\n",
        "\n",
        "print(id_to_word(train_data[0:100]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBnJnxJLeL-n",
        "outputId": "843908d7-0a89-44b2-c1c0-fcc582af4244"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['aer', 'banknote', 'berlitz', 'calloway', 'centrust', 'cluett', 'fromstein', 'gitano', 'guterman', 'hydro-quebec', 'ipo', 'kia', 'memotec', 'mlx', 'nahb', 'punts', 'rake', 'regatta', 'rubens', 'sim', 'snack-food', 'ssangyong', 'swapo', 'wachter', '<eos>', 'pierre', '<unk>', 'N', 'years', 'old', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'nov.', 'N', '<eos>', 'mr.', '<unk>', 'is', 'chairman', 'of', '<unk>', 'n.v.', 'the', 'dutch', 'publishing', 'group', '<eos>', 'rudolph', '<unk>', 'N', 'years', 'old', 'and', 'former', 'chairman', 'of', 'consolidated', 'gold', 'fields', 'plc', 'was', 'named', 'a', 'nonexecutive', 'director', 'of', 'this', 'british', 'industrial', 'conglomerate', '<eos>', 'a', 'form', 'of', 'asbestos', 'once', 'used', 'to', 'make', 'kent', 'cigarette', 'filters', 'has', 'caused', 'a', 'high', 'percentage', 'of', 'cancer', 'deaths', 'among', 'a', 'group', 'of']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets just read one mini-batch now and feed our network:\n"
      ],
      "metadata": {
        "id": "46KPJTHZeVnH"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "itera=reader.ptb_iterator(train_data,batch_size,num_steps)\n",
        "first_touple = itera.__next__()\n",
        "_input_data = first_touple[0]\n",
        "_targets = first_touple[1]"
      ],
      "metadata": {
        "id": "tgqvNiPieXp4"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_input_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ck0AVbpxerjP",
        "outputId": "fcfe027e-87bf-4f60-9367-aa21a053b2ea"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_targets.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrgPgwY7es7f",
        "outputId": "9f382b74-ab71-4c60-cc18-f4b38473a7b6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets look at 3 sentences of our input x:"
      ],
      "metadata": {
        "id": "p-vXkRXCeuwf"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_input_data[0:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCRyOo4NexRv",
        "outputId": "f3233839-0710-48bd-d55a-9b1b7115ea04"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9970, 9971, 9972, 9974, 9975, 9976, 9980, 9981, 9982, 9983, 9984,\n",
              "        9986, 9987, 9988, 9989, 9991, 9992, 9993, 9994, 9995],\n",
              "       [2654,    6,  334, 2886,    4,    1,  233,  711,  834,   11,  130,\n",
              "         123,    7,  514,    2,   63,   10,  514,    8,  605],\n",
              "       [   0, 1071,    4,    0,  185,   24,  368,   20,   31, 3109,  954,\n",
              "          12,    3,   21,    2, 2915,    2,   12,    3,   21]],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(id_to_word(_input_data[0,:]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXunJDuAeyh3",
        "outputId": "4fd51d0e-c455-478a-a38b-2db47f46a79a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['aer', 'banknote', 'berlitz', 'calloway', 'centrust', 'cluett', 'fromstein', 'gitano', 'guterman', 'hydro-quebec', 'ipo', 'kia', 'memotec', 'mlx', 'nahb', 'punts', 'rake', 'regatta', 'rubens', 'sim']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EMBEDDINGS\n",
        "---"
      ],
      "metadata": {
        "id": "25XQtEARe_Eo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = tf.keras.layers.Embedding(vocab_size, embeding_vector_size,trainable=True,name=\"embedding_vocab\")"
      ],
      "metadata": {
        "id": "iIgSskRDe4DX"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define where to get the data for our embeddings from\n",
        "inputs = embedding_layer(_input_data)\n",
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvlIict6fUXJ",
        "outputId": "0ca287e9-f586-4d4e-a7f2-d0d7f1dc8bd0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30, 20, 200), dtype=float32, numpy=\n",
              "array([[[-0.01436456,  0.0440993 , -0.02107005, ...,  0.01413027,\n",
              "         -0.01145139, -0.03084683],\n",
              "        [ 0.04215157, -0.02009675, -0.02407203, ..., -0.00023391,\n",
              "          0.04727561, -0.01329543],\n",
              "        [ 0.00682461, -0.02996184,  0.00371871, ...,  0.03537413,\n",
              "         -0.03849957, -0.00537307],\n",
              "        ...,\n",
              "        [ 0.04776729, -0.01894908, -0.00567423, ...,  0.02156867,\n",
              "         -0.03187786,  0.01174675],\n",
              "        [-0.0490693 ,  0.0273697 ,  0.00766647, ...,  0.02603543,\n",
              "          0.01303884,  0.00227611],\n",
              "        [ 0.03717044, -0.02521272,  0.04218866, ...,  0.02438002,\n",
              "         -0.0119619 , -0.02224101]],\n",
              "\n",
              "       [[-0.0186911 , -0.02416588, -0.02485015, ...,  0.02687794,\n",
              "         -0.03799218, -0.03854796],\n",
              "        [ 0.01473199, -0.02374755,  0.02031913, ...,  0.03837327,\n",
              "          0.03252325,  0.04618504],\n",
              "        [-0.02834617,  0.00438561, -0.00953913, ..., -0.00511362,\n",
              "          0.0188951 , -0.02685125],\n",
              "        ...,\n",
              "        [ 0.00312169, -0.02114366, -0.04770496, ...,  0.01387003,\n",
              "          0.01629294, -0.00091667],\n",
              "        [ 0.01300919, -0.01377242, -0.0330014 , ...,  0.01093855,\n",
              "         -0.0454666 ,  0.01280445],\n",
              "        [ 0.00800325, -0.02209128, -0.00412382, ..., -0.02551367,\n",
              "         -0.04957641, -0.01600093]],\n",
              "\n",
              "       [[-0.01740701,  0.00605287,  0.03567332, ..., -0.04541438,\n",
              "         -0.03923575, -0.01740671],\n",
              "        [-0.0478879 , -0.0012674 ,  0.01912284, ...,  0.04544565,\n",
              "         -0.01104997, -0.01811033],\n",
              "        [ 0.04874614,  0.04515758,  0.0199105 , ..., -0.0300722 ,\n",
              "          0.03583665, -0.02927566],\n",
              "        ...,\n",
              "        [ 0.04431899,  0.02415581,  0.0175434 , ...,  0.02666301,\n",
              "          0.01243869,  0.0446151 ],\n",
              "        [-0.04241952, -0.03334622, -0.04795816, ...,  0.03325404,\n",
              "          0.02476454, -0.01185362],\n",
              "        [-0.03910221, -0.04308556, -0.04847705, ..., -0.0483479 ,\n",
              "          0.02536389, -0.03134463]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 0.02513037, -0.00460913,  0.044662  , ...,  0.00149754,\n",
              "          0.044289  , -0.00013288],\n",
              "        [-0.01871343, -0.0421873 ,  0.04027719, ..., -0.00357927,\n",
              "         -0.03352828,  0.03207698],\n",
              "        [ 0.00479888, -0.03645904, -0.03883929, ...,  0.02323501,\n",
              "         -0.04325097, -0.01783771],\n",
              "        ...,\n",
              "        [-0.02930352,  0.00990785, -0.03613104, ..., -0.01032283,\n",
              "          0.04385474, -0.01619437],\n",
              "        [ 0.02486629, -0.00650481,  0.0425194 , ..., -0.04801539,\n",
              "         -0.01693183,  0.01485375],\n",
              "        [ 0.04046882,  0.01090487,  0.01203905, ...,  0.02024052,\n",
              "          0.00848823, -0.01608689]],\n",
              "\n",
              "       [[ 0.03248303, -0.00761812, -0.03946053, ...,  0.03546337,\n",
              "          0.01188046,  0.00054332],\n",
              "        [ 0.03560176,  0.02529821, -0.0148615 , ...,  0.00752859,\n",
              "          0.0303016 ,  0.01703678],\n",
              "        [ 0.04874614,  0.04515758,  0.0199105 , ..., -0.0300722 ,\n",
              "          0.03583665, -0.02927566],\n",
              "        ...,\n",
              "        [-0.01920268,  0.03045872, -0.00012233, ...,  0.0058744 ,\n",
              "          0.01724062, -0.04376509],\n",
              "        [ 0.01473199, -0.02374755,  0.02031913, ...,  0.03837327,\n",
              "          0.03252325,  0.04618504],\n",
              "        [-0.02187053,  0.03290648,  0.04639233, ...,  0.01576105,\n",
              "          0.04396428,  0.04225368]],\n",
              "\n",
              "       [[ 0.04625665, -0.0047575 , -0.01885049, ..., -0.0093746 ,\n",
              "         -0.04141269,  0.00531898],\n",
              "        [-0.03254186, -0.00105667, -0.02227534, ..., -0.04149679,\n",
              "          0.03980551, -0.02412503],\n",
              "        [-0.02836431,  0.04423771,  0.02014462, ...,  0.02868129,\n",
              "         -0.01588098,  0.04592444],\n",
              "        ...,\n",
              "        [-0.04824202, -0.00871428,  0.03179504, ..., -0.0146899 ,\n",
              "         -0.04014115,  0.04756734],\n",
              "        [ 0.03890382,  0.0044744 ,  0.03023552, ..., -0.0004519 ,\n",
              "          0.00396565,  0.01977025],\n",
              "        [-0.04810404,  0.02006416,  0.03709653, ...,  0.04543402,\n",
              "          0.01673042,  0.04022155]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Constructing Recurrent Neural Networks</h3>\n"
      ],
      "metadata": {
        "id": "H67W9_kDfgE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_cell_l1 = tf.keras.layers.LSTMCell(hidden_size_l1)\n",
        "lstm_cell_l2 = tf.keras.layers.LSTMCell(hidden_size_l2)"
      ],
      "metadata": {
        "id": "n_cO8krvfgcA"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stacked_lstm = tf.keras.layers.StackedRNNCells([lstm_cell_l1, lstm_cell_l2])"
      ],
      "metadata": {
        "id": "4IKfgGvGfjFJ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer  =  tf.keras.layers.RNN(stacked_lstm,[batch_size, num_steps],return_state=False,stateful=True,trainable=True)"
      ],
      "metadata": {
        "id": "MemxVAqBfkXR"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "init_state = tf.Variable(tf.zeros([batch_size,embeding_vector_size]),trainable=False)"
      ],
      "metadata": {
        "id": "r6_JnwKlfm7I"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer.inital_state = init_state"
      ],
      "metadata": {
        "id": "wiQN5tv-fqbp"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer.inital_state"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzfBJ40Ffr9R",
        "outputId": "e11a30cc-10cc-4718-d208-6648ad74cfaf"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(30, 200) dtype=float32, numpy=\n",
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = layer(inputs)"
      ],
      "metadata": {
        "id": "Lx1VES9qfujR"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSLZ5LXzfwqh",
        "outputId": "e42599dc-4d64-4df8-d22a-3ecd1fa44ced"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30, 20, 128), dtype=float32, numpy=\n",
              "array([[[-1.6887874e-03, -2.2335418e-05, -9.2224707e-04, ...,\n",
              "         -3.0881836e-07,  1.3239472e-03,  4.9628405e-04],\n",
              "        [-1.9791326e-03,  2.6744499e-04, -1.4664220e-03, ...,\n",
              "         -2.3299240e-04,  2.8962109e-03,  1.2438344e-03],\n",
              "        [-4.8868014e-03,  1.2401775e-04, -2.6096166e-03, ...,\n",
              "          2.6333935e-04,  4.0177279e-03,  3.3195566e-03],\n",
              "        ...,\n",
              "        [-1.2695015e-04,  4.7474657e-03,  1.6818448e-03, ...,\n",
              "          9.6982246e-04, -1.7865861e-03,  1.1568234e-03],\n",
              "        [ 2.1898847e-03,  4.0006372e-03,  3.9001126e-03, ...,\n",
              "         -1.8554339e-03, -3.1012679e-03,  1.5256708e-03],\n",
              "        [ 3.9156834e-03,  2.2908205e-03,  3.8792619e-03, ...,\n",
              "         -3.2028779e-03, -3.0979966e-03,  1.5841797e-03]],\n",
              "\n",
              "       [[-1.5331253e-03, -7.0395449e-04,  1.2044576e-05, ...,\n",
              "          3.3090562e-06,  4.6755350e-04, -1.2553754e-03],\n",
              "        [-2.4340677e-03, -1.7228093e-03, -5.1922735e-04, ...,\n",
              "          4.5084156e-04,  6.3757488e-04, -1.3746927e-03],\n",
              "        [-2.0642225e-03, -2.0811495e-03, -7.9796318e-04, ...,\n",
              "          7.6594442e-04,  1.8329431e-03, -1.5868982e-03],\n",
              "        ...,\n",
              "        [ 1.4013218e-03, -3.6271135e-03,  3.9651566e-03, ...,\n",
              "         -5.0752391e-03,  2.0122230e-03,  7.5408100e-04],\n",
              "        [ 1.2641177e-03, -2.8696402e-03,  6.8967086e-03, ...,\n",
              "         -7.1456735e-03,  2.4232303e-03,  9.3733863e-04],\n",
              "        [ 1.7056370e-03, -2.2022470e-03,  7.1483706e-03, ...,\n",
              "         -7.6869973e-03,  1.7977573e-03, -1.0456975e-03]],\n",
              "\n",
              "       [[ 8.5146580e-04,  8.1398786e-04, -6.4102111e-05, ...,\n",
              "          1.4166967e-03, -2.2249956e-04,  1.2504851e-03],\n",
              "        [ 3.8980821e-04,  2.1361712e-04, -1.5142461e-04, ...,\n",
              "          1.9841646e-03,  3.4763603e-04,  1.5434037e-03],\n",
              "        [-1.7851469e-03,  9.2443841e-04, -3.2126356e-04, ...,\n",
              "          1.3389678e-03,  1.3634891e-03,  4.2620112e-04],\n",
              "        ...,\n",
              "        [-2.5242309e-03,  1.3779625e-03,  5.8083837e-03, ...,\n",
              "         -5.3234622e-03, -7.3511369e-04, -8.2067363e-03],\n",
              "        [-2.9751959e-03,  1.1755504e-03,  6.7877877e-03, ...,\n",
              "         -6.4474400e-03, -1.1794555e-03, -7.9117883e-03],\n",
              "        [-3.2114801e-03,  2.0715254e-03,  8.1758965e-03, ...,\n",
              "         -7.5694812e-03, -2.2084343e-04, -7.6425974e-03]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 9.6391392e-04,  2.7828725e-04,  9.5663039e-05, ...,\n",
              "          1.5061510e-04, -1.4783832e-03,  1.0550943e-03],\n",
              "        [-1.5176304e-04, -2.2869301e-04, -2.8489827e-04, ...,\n",
              "          6.6461443e-04, -3.1647799e-03,  2.3119450e-03],\n",
              "        [-7.1553543e-04, -7.0707686e-04, -2.4367773e-04, ...,\n",
              "          5.0981255e-04, -2.1229296e-03,  3.7929199e-03],\n",
              "        ...,\n",
              "        [-1.9635244e-03,  6.5187905e-03,  8.5450765e-03, ...,\n",
              "          9.1199792e-04,  7.4899588e-03,  1.4307977e-03],\n",
              "        [-6.7695620e-04,  6.4381412e-03,  9.0625957e-03, ...,\n",
              "          9.3100761e-04,  7.1309204e-03, -6.1857770e-04],\n",
              "        [-1.7354065e-03,  5.3725429e-03,  8.4744394e-03, ...,\n",
              "         -4.5831894e-04,  7.4596265e-03, -1.0871647e-03]],\n",
              "\n",
              "       [[ 5.5160967e-04,  2.4980359e-04, -7.7092566e-04, ...,\n",
              "         -4.2347671e-04, -5.7040085e-04, -5.8651454e-04],\n",
              "        [ 7.9933088e-04,  1.2488441e-03, -1.3910065e-03, ...,\n",
              "         -1.0671039e-03,  3.5678939e-04, -8.1643625e-04],\n",
              "        [-9.6770155e-04,  2.5743172e-03, -2.0044371e-03, ...,\n",
              "         -2.5792923e-03,  1.2286659e-03, -1.8662938e-03],\n",
              "        ...,\n",
              "        [ 2.6757629e-03,  7.5081280e-03,  9.1333111e-04, ...,\n",
              "          2.6846132e-03, -1.6439423e-03, -3.2308777e-05],\n",
              "        [ 3.1090854e-03,  6.3894279e-03, -1.0135994e-04, ...,\n",
              "          3.7500197e-03, -1.5021249e-03,  1.1211265e-03],\n",
              "        [ 1.5287992e-03,  6.9247531e-03,  8.1663631e-04, ...,\n",
              "          3.7661085e-03, -1.3683153e-03,  5.4977025e-04]],\n",
              "\n",
              "       [[ 1.4683101e-03,  7.8273576e-04,  3.7001373e-04, ...,\n",
              "          5.5032244e-05,  6.1584805e-04,  1.1086855e-03],\n",
              "        [ 3.4438379e-03,  3.0495441e-03,  2.0679189e-03, ...,\n",
              "          3.0970396e-04,  1.0937796e-03,  1.8379876e-03],\n",
              "        [ 5.1972568e-03,  3.4283670e-03,  3.0499313e-03, ...,\n",
              "          9.9433633e-04,  1.9908305e-03,  1.3354644e-03],\n",
              "        ...,\n",
              "        [ 6.7158486e-03, -6.8094539e-03,  2.6980292e-03, ...,\n",
              "          5.1425892e-04, -2.2615800e-03, -5.0081415e-03],\n",
              "        [ 5.8910665e-03, -8.1022652e-03,  2.1431949e-03, ...,\n",
              "          1.8857108e-04, -1.6551083e-03, -6.2436401e-03],\n",
              "        [ 5.3954218e-03, -7.7246963e-03,  1.4637503e-03, ...,\n",
              "          4.5492389e-04, -9.1370230e-04, -6.7518498e-03]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Dense layer</h2>\n",
        "We now create densely-connected neural network layer that would reshape the outputs tensor from  [30 x 20 x 128] to [30 x 20 x 10000].\n"
      ],
      "metadata": {
        "id": "HF-Jyo5Df0bz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dense = tf.keras.layers.Dense(vocab_size)"
      ],
      "metadata": {
        "id": "370uI-cff0vh"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits_outputs  = dense(outputs)"
      ],
      "metadata": {
        "id": "Gtg-ZjL7f4zx"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"shape of the output from dense layer: \", logits_outputs.shape) #(batch_size, sequence_length, vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zg4O5wPpf6Eh",
        "outputId": "2f58046b-ac48-46d1-bcf4-e0e0b09908c5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of the output from dense layer:  (30, 20, 10000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Activation layer</h2>\n",
        "\n",
        "A softmax activation layers is also then applied to derive the probability of the output being in any of the multiclass(10000 in this case) possibilities.\n"
      ],
      "metadata": {
        "id": "owtItqYyf999"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "activation = tf.keras.layers.Activation('softmax')"
      ],
      "metadata": {
        "id": "iN1OlDG6f9BA"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_words_prob = activation(logits_outputs)"
      ],
      "metadata": {
        "id": "eIqogo5-gAkZ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"shape of the output from the activation layer: \", output_words_prob.shape) #(batch_size, sequence_length, vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYZs67IogBpD",
        "outputId": "ca75f044-0fa2-45e9-d3c1-73054bf141e1"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of the output from the activation layer:  (30, 20, 10000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The probability of observing words in t=0 to t=20\", output_words_prob[0,0:num_steps])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j70-7E13gCxq",
        "outputId": "1d2a237f-c45e-4d58-e054-4abdf7e9f1fa"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The probability of observing words in t=0 to t=20 tf.Tensor(\n",
            "[[9.99818440e-05 1.00003665e-04 1.00012316e-04 ... 9.99896438e-05\n",
            "  1.00009645e-04 9.99818658e-05]\n",
            " [9.99781550e-05 9.99867480e-05 1.00017118e-04 ... 9.99580807e-05\n",
            "  1.00000339e-04 9.99592303e-05]\n",
            " [1.00004509e-04 9.99633921e-05 1.00000783e-04 ... 9.99492331e-05\n",
            "  9.99800395e-05 9.99444383e-05]\n",
            " ...\n",
            " [9.99958647e-05 1.00013021e-04 1.00026082e-04 ... 1.00032652e-04\n",
            "  9.99937693e-05 9.98087853e-05]\n",
            " [9.99842814e-05 1.00015575e-04 1.00016900e-04 ... 1.00066092e-04\n",
            "  1.00006720e-04 9.97996030e-05]\n",
            " [9.99673139e-05 1.00008918e-04 1.00030848e-04 ... 1.00091493e-04\n",
            "  9.99956101e-05 9.97943280e-05]], shape=(20, 10000), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Prediction</h3>\n",
        "What is the word correspond to the probability output? Lets use the maximum probability:\n"
      ],
      "metadata": {
        "id": "2pv4a5MkgGxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(output_words_prob[0,0:num_steps], axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J46cpoXrgHMq",
        "outputId": "a9241772-b01c-4328-cb2f-688cd6340c4e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([8244, 5314, 5258, 5258, 5258, 2009, 2009, 2009, 2009, 2009, 2391,\n",
              "       2391, 8010, 1848, 9846, 1317, 1317, 1317, 1317, 8012])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_targets[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doYVLmF7gIqZ",
        "outputId": "42980c41-f724-45ce-b36c-c8c063b7a9f7"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9971, 9972, 9974, 9975, 9976, 9980, 9981, 9982, 9983, 9984, 9986,\n",
              "       9987, 9988, 9989, 9991, 9992, 9993, 9994, 9995, 9996], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4>Objective function</h4>\n",
        "\n",
        "How similar the predicted words are to the target words?\n",
        "\n",
        "Now we have to define our objective function, to calculate the similarity of predicted values to ground truth, and then, penalize the model with the error. Our objective is to minimize loss function, that is, to minimize the average negative log probability of the target words:\n",
        "\n",
        "$$\\text{loss} = -\\frac{1}{N}\\sum_{i=1}^{N} \\ln p_{\\text{target}\\_i}$$\n",
        "\n",
        "This function is already implemented and available in TensorFlow through _tf.keras.losses.sparse_categorical_crossentropy_. It calculates the categorical cross-entropy loss for <b>logits</b> and the <b>target</b> sequence.  \n",
        "\n",
        "The arguments of this function are:  \n",
        "\n",
        "<ul>\n",
        "    <li>logits: List of 2D Tensors of shape [batch_size x num_decoder_symbols].</li>  \n",
        "    <li>targets: List of 1D batch-sized int32 Tensors of the same length as logits.</li>   \n",
        "</ul>\n"
      ],
      "metadata": {
        "id": "Mk58SGbsgLjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def crossentropy(y_true, y_pred):\n",
        "    return tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred)"
      ],
      "metadata": {
        "id": "SRfliETRgL3q"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss  = crossentropy(_targets, output_words_prob)"
      ],
      "metadata": {
        "id": "G6sTnOqagOeC"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss[0,:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4Xc29NUgPqC",
        "outputId": "634e3445-3382-496d-f1c3-6c6910d1096b"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
              "array([9.210186, 9.210302, 9.210356, 9.209693, 9.210658, 9.21028 ,\n",
              "       9.210519, 9.211017, 9.209904, 9.211192], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cost = tf.reduce_sum(loss / batch_size)\n",
        "cost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IDDA0DIgQ8D",
        "outputId": "a62dc705-39c4-4441-b5bc-e552d29c56de"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=184.207763671875>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Training</h3>\n",
        "\n",
        "To do training for our network, we have to take the following steps:\n",
        "\n",
        "<ol>\n",
        "    <li>Define the optimizer.</li>\n",
        "    <li>Assemble layers to build model.</li>\n",
        "    <li>Calculate the gradients based on the loss function.</li>\n",
        "    <li>Apply the optimizer to the variables/gradients tuple.</li>\n",
        "</ol>\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kMl2nKgJgU8C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4>1. Define Optimizer</h4>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Guwmv9BGgcp2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a variable for the learning rate\n",
        "lr = tf.Variable(0.0, trainable=False)\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, clipnorm=max_grad_norm)"
      ],
      "metadata": {
        "id": "Y6i68w0Fgfji"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4>2. Assemble layers to build model.</h4>\n"
      ],
      "metadata": {
        "id": "LQ76Y6qmgsaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(embedding_layer)\n",
        "model.add(layer)\n",
        "model.add(dense)\n",
        "model.add(activation)\n",
        "model.compile(loss=crossentropy, optimizer=optimizer)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "SA6iDHVaggsD",
        "outputId": "78a69546-a7bc-4b09-c085-e4691cb205de"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_vocab (\u001b[38;5;33mEmbedding\u001b[0m)     │ (\u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m200\u001b[0m)          │     \u001b[38;5;34m2,000,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ rnn (\u001b[38;5;33mRNN\u001b[0m)                       │ (\u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │       \u001b[38;5;34m665,088\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m10000\u001b[0m)        │     \u001b[38;5;34m1,290,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_vocab (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,000,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RNN</span>)                       │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">665,088</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10000</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,955,088\u001b[0m (15.09 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,955,088</span> (15.09 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,955,088\u001b[0m (15.09 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,955,088</span> (15.09 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4>2. Trainable Variables</h4>\n"
      ],
      "metadata": {
        "id": "V_B_7kITgxiG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining a variable, if you passed <i>trainable=True</i>, the variable constructor automatically adds new variables to the graph collection <b>GraphKeys.TRAINABLE_VARIABLES</b>. Now, using <i>tf.trainable_variables()</i> you can get all variables created with <b>trainable=True</b>.\n"
      ],
      "metadata": {
        "id": "cNuiaIvigyip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all TensorFlow variables marked as \"trainable\" (i.e. all of them except _lr, which we just created)\n",
        "tvars = model.trainable_variables"
      ],
      "metadata": {
        "id": "Xl4Sb4qRg58K"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: we can find the name and scope of all variables:\n"
      ],
      "metadata": {
        "id": "koJVoB06g5Qx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[v.name for v in tvars]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1tSyRxeg-JE",
        "outputId": "7d63e603-7e20-4f14-f881-dba0010ec070"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['embeddings',\n",
              " 'kernel',\n",
              " 'recurrent_kernel',\n",
              " 'bias',\n",
              " 'kernel',\n",
              " 'recurrent_kernel',\n",
              " 'bias',\n",
              " 'kernel',\n",
              " 'bias']"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4>3. Calculate the gradients based on the loss function</h4>\n",
        "**Gradient**: The gradient of a function is the slope of its derivative (line), or in other words, the rate of change of a function. It's a vector (a direction to move) that points in the direction of greatest increase of the function, and calculated by the <b>derivative</b> operation.\n",
        "First lets recall the gradient function using an toy example:\n",
        "$$ z = \\left(2x^2 + 3xy\\right)$$\n"
      ],
      "metadata": {
        "id": "suC2ZLzPgyoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.constant(1.0)\n",
        "y =  tf.constant(2.0)\n",
        "with tf.GradientTape(persistent=True) as g:\n",
        "    g.watch(x)\n",
        "    g.watch(y)\n",
        "    func_test = 2 * x * x + 3 * x * y"
      ],
      "metadata": {
        "id": "cv2pAiGlhBJh"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The <b>tf.gradients()</b> function allows you to compute the symbolic gradient of one tensor with respect to one or more other tensors—including variables. <b>tf.gradients(func, xs)</b> constructs symbolic partial derivatives of sum of <b>func</b> w.r.t. <i>x</i> in <b>xs</b>.\n",
        "\n",
        "Now, lets look at the derivitive w.r.t. <b>var_x</b>:\n",
        "$$ \\frac{\\partial \\:}{\\partial \\:x}\\left(2x^2 + 3xy\\right) = 4x + 3y $$\n"
      ],
      "metadata": {
        "id": "9GcOH89vgyrr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "var_grad = g.gradient(func_test, x) # Will compute to 10.0\n",
        "print(var_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uj7tNXffhK4U",
        "outputId": "2dc9d7e2-0a1d-4ec3-f4a6-873867e1a77f"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(10.0, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the derivative w.r.t. <b>var_y</b>:\n",
        "$$ \\frac{\\partial \\:}{\\partial \\:y}\\left(2x^2 + 3xy\\right) = 3x $$\n"
      ],
      "metadata": {
        "id": "NlQ7Wf15hOSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "var_grad = g.gradient(func_test, y) # Will compute to 3.0\n",
        "print(var_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDhSbPvchQFJ",
        "outputId": "5110d123-f3fa-4c2b-d79e-7bdbb7a74de5"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(3.0, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can look at gradients w.r.t all variables:\n"
      ],
      "metadata": {
        "id": "_15ExVCmhSfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.GradientTape() as tape:\n",
        "    # Forward pass.\n",
        "    output_words_prob = model(_input_data)\n",
        "    # Loss value for this batch.\n",
        "    loss  = crossentropy(_targets, output_words_prob)\n",
        "    cost = tf.reduce_sum(loss,axis=0) / batch_size"
      ],
      "metadata": {
        "id": "V8DX_FkbhQgF"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get gradients of loss wrt the trainable variables.\n",
        "grad_t_list = tape.gradient(cost, tvars)"
      ],
      "metadata": {
        "id": "dKQ6cLEdhTzW"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(grad_t_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBbKmvyUhVcd",
        "outputId": "ce8aafbb-ffab-4d1b-f42f-8ce5d32248e7"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x78289d2346d0>, <tf.Tensor: shape=(200, 1024), dtype=float32, numpy=\n",
            "array([[-6.6341090e-07, -1.7943911e-06,  1.2738228e-06, ...,\n",
            "         1.4700987e-06, -1.9430928e-09,  1.8701965e-07],\n",
            "       [-1.1954504e-07, -8.6421505e-07,  2.6428540e-07, ...,\n",
            "         2.5293861e-07,  1.8830329e-07, -6.4357785e-08],\n",
            "       [-9.1166379e-07, -1.0903372e-06, -1.3817676e-06, ...,\n",
            "         8.6296490e-07,  2.2890774e-07, -2.4464435e-07],\n",
            "       ...,\n",
            "       [ 9.2097594e-08, -2.2139028e-07,  5.9687051e-07, ...,\n",
            "        -4.1208261e-07, -8.1399963e-07,  3.2546933e-07],\n",
            "       [ 5.7409784e-07,  3.2205017e-07,  8.2884753e-07, ...,\n",
            "         3.1615627e-07, -1.4287221e-07,  5.7324735e-07],\n",
            "       [ 2.3974297e-07,  1.8661331e-07, -1.1566767e-06, ...,\n",
            "         3.6195331e-08, -2.9375056e-07, -1.0501839e-07]], dtype=float32)>, <tf.Tensor: shape=(256, 1024), dtype=float32, numpy=\n",
            "array([[ 2.48230947e-07,  6.90864255e-08, -3.91676167e-08, ...,\n",
            "        -5.76186324e-07,  3.17301208e-08, -3.51071314e-08],\n",
            "       [ 1.39880029e-07, -2.06876166e-07, -3.01223508e-08, ...,\n",
            "         2.30878570e-07,  4.72560870e-08, -1.03256994e-07],\n",
            "       [-1.25245485e-08, -1.11857688e-07, -2.05892377e-07, ...,\n",
            "         7.96272161e-07,  5.08743057e-08, -1.45689910e-07],\n",
            "       ...,\n",
            "       [-1.37991947e-07, -5.00081541e-08, -1.79421875e-07, ...,\n",
            "         1.53559097e-06, -6.20987493e-08, -1.70686334e-07],\n",
            "       [-4.87362648e-08,  6.67419897e-08,  7.52084617e-10, ...,\n",
            "        -6.77902221e-07, -2.09715623e-07,  8.91903262e-09],\n",
            "       [ 1.45648613e-08, -4.49105642e-10,  3.01994987e-07, ...,\n",
            "        -4.03727313e-07, -8.51402007e-08,  1.74455010e-07]], dtype=float32)>, <tf.Tensor: shape=(1024,), dtype=float32, numpy=\n",
            "array([-1.97362642e-05,  1.38577525e-06, -1.39434505e-05, ...,\n",
            "        1.09518514e-04,  1.70518160e-06, -1.31859051e-05], dtype=float32)>, <tf.Tensor: shape=(256, 512), dtype=float32, numpy=\n",
            "array([[ 1.0003672e-07, -1.8315536e-07,  9.2712277e-08, ...,\n",
            "        -2.3051783e-07,  2.8799468e-07, -3.0240651e-07],\n",
            "       [-1.3492632e-07, -3.7076217e-07,  7.6814004e-08, ...,\n",
            "        -3.7342772e-08, -3.5162671e-08,  1.7742528e-07],\n",
            "       [-3.4354684e-08, -9.7082015e-08, -9.1791623e-09, ...,\n",
            "        -6.5315874e-07, -2.0342924e-07,  3.7967646e-07],\n",
            "       ...,\n",
            "       [-1.1480187e-07,  2.6787731e-08,  1.5360928e-07, ...,\n",
            "        -2.3742673e-07, -4.4051237e-08,  3.0338629e-07],\n",
            "       [ 1.2744434e-07, -6.2218035e-09, -1.5077834e-08, ...,\n",
            "        -4.8772677e-07,  2.7561015e-07, -3.9644561e-07],\n",
            "       [-6.4335275e-09,  8.9673684e-08, -7.4075146e-08, ...,\n",
            "        -3.8872986e-07,  1.2266572e-07, -3.2854462e-07]], dtype=float32)>, <tf.Tensor: shape=(128, 512), dtype=float32, numpy=\n",
            "array([[-2.45507465e-07, -2.34891218e-08,  1.34933131e-08, ...,\n",
            "         1.25672670e-07,  8.60563265e-09,  2.69166041e-08],\n",
            "       [ 9.36552524e-08,  3.36090750e-07, -3.06653085e-08, ...,\n",
            "        -2.07855742e-08,  1.98790602e-08,  9.77043442e-08],\n",
            "       [-1.29785590e-07,  7.31448964e-08, -1.44647458e-07, ...,\n",
            "         2.07128437e-07,  4.85118115e-08,  1.73954518e-07],\n",
            "       ...,\n",
            "       [-1.63965396e-07, -3.78249254e-08,  2.93489592e-07, ...,\n",
            "        -4.99750627e-07, -1.72583743e-08, -1.19292281e-07],\n",
            "       [ 2.22653256e-08, -1.38404303e-07,  3.87632255e-08, ...,\n",
            "         5.20002104e-08, -3.00967429e-08,  7.84287568e-09],\n",
            "       [ 2.38956517e-08,  8.92155185e-08, -2.95615834e-08, ...,\n",
            "         9.89713911e-08,  1.04824316e-07, -4.42154885e-07]], dtype=float32)>, <tf.Tensor: shape=(512,), dtype=float32, numpy=\n",
            "array([-8.27287204e-06,  2.42986789e-06,  2.99144212e-05,  9.77059972e-06,\n",
            "       -6.61772106e-07, -4.89284639e-06,  7.43267356e-06, -4.98777299e-05,\n",
            "        3.44762748e-06, -2.67436881e-05,  4.39580690e-05, -2.41312409e-06,\n",
            "        1.49732705e-05,  8.39675704e-06,  1.58637467e-05,  6.83307589e-05,\n",
            "       -1.09334887e-05, -7.52532796e-05, -2.75037964e-05,  2.46473501e-05,\n",
            "       -7.01034151e-06,  8.89881812e-06,  4.40342737e-05,  1.17747823e-06,\n",
            "       -2.61652658e-05,  3.69978006e-05,  4.74753688e-06,  3.81383543e-05,\n",
            "       -1.89488455e-05, -2.78850484e-06, -3.79353878e-06,  9.39883648e-06,\n",
            "       -3.55833254e-05, -1.15260696e-06, -4.19075423e-06,  2.27818637e-05,\n",
            "       -2.51799520e-06, -5.08688172e-05, -2.12781124e-05,  3.18023085e-05,\n",
            "        4.85332421e-05,  1.17219197e-05,  1.40593656e-05, -2.82514848e-05,\n",
            "        4.71851854e-05,  2.32980055e-05,  2.64546270e-05,  4.63524702e-05,\n",
            "        7.16754403e-06,  1.52473749e-05, -3.87958153e-06,  4.85630226e-05,\n",
            "        3.16046680e-07, -1.92421794e-06,  9.70056280e-05, -2.24246596e-05,\n",
            "        1.87356054e-05, -3.59596379e-06, -3.73113949e-06,  8.29334112e-06,\n",
            "        5.94078338e-05, -5.82126959e-05, -4.89686427e-05, -6.26651854e-06,\n",
            "       -6.24077875e-05, -1.95451612e-05, -1.75345394e-06, -2.52567443e-05,\n",
            "       -7.19027739e-05,  2.57731131e-06, -3.48911854e-05,  2.77004074e-05,\n",
            "       -4.53034882e-05,  2.64862210e-05,  8.02370596e-06,  2.14215343e-05,\n",
            "        2.42730057e-05,  3.12372285e-05,  9.81087433e-05, -7.15221177e-07,\n",
            "       -1.50061769e-05, -8.18678454e-05,  1.86900452e-05, -4.04879320e-05,\n",
            "       -3.37007555e-06, -3.18693164e-05,  3.45997978e-06, -8.67399358e-05,\n",
            "        2.90240296e-05,  7.86883247e-05, -1.32372215e-05,  3.44234468e-06,\n",
            "        2.31873146e-05,  3.26161098e-05, -2.72523630e-05, -5.37690630e-06,\n",
            "        5.04463642e-05, -3.00664906e-05,  1.35263781e-05, -1.84616492e-05,\n",
            "       -1.43503112e-05, -7.57593398e-06,  1.46552320e-05, -9.82609981e-06,\n",
            "        1.46076845e-05,  1.01433288e-05,  1.31565012e-05, -1.69745588e-04,\n",
            "       -1.30933313e-05,  2.39807596e-05, -3.50999971e-06, -1.81861269e-05,\n",
            "        2.91861215e-05, -1.37549641e-05,  6.90855813e-05,  5.58792381e-05,\n",
            "        1.93699943e-05,  3.30529183e-05, -1.36619783e-05,  2.20918173e-05,\n",
            "       -3.07503251e-05,  3.47082678e-05,  5.19444075e-05,  2.91172964e-05,\n",
            "        9.19579543e-06,  5.05988392e-05, -3.27931266e-05,  6.19021739e-05,\n",
            "       -6.56905922e-06, -2.58390774e-05,  1.25876577e-05,  2.71560057e-05,\n",
            "        4.82432461e-06, -3.14191821e-05,  2.06333734e-05, -8.90538067e-05,\n",
            "        1.26681189e-05, -7.78348112e-06,  5.55052975e-05, -2.22825429e-06,\n",
            "        2.09288755e-05, -1.00098168e-05,  1.89091588e-05,  7.40004616e-05,\n",
            "        1.79134076e-06, -8.90458759e-05,  1.37164534e-06,  2.31195972e-05,\n",
            "        1.10742176e-05,  1.40395323e-05,  4.88866026e-05, -1.31521065e-05,\n",
            "       -4.83218173e-05,  3.99566707e-05, -1.14668137e-05,  5.84517729e-05,\n",
            "       -3.17670037e-06,  8.66497703e-06, -3.21629923e-05, -9.46541149e-06,\n",
            "       -3.45106164e-05, -3.02835779e-05,  3.80030979e-05,  3.31493939e-05,\n",
            "       -1.53465680e-05, -3.36683661e-05, -2.55684008e-05,  3.42316998e-05,\n",
            "        3.55028169e-05,  1.36976578e-05,  1.20525674e-05, -3.13451019e-05,\n",
            "        6.95993222e-05,  4.45724654e-05,  5.00133829e-05,  3.98605916e-05,\n",
            "       -5.97468897e-07, -1.09309321e-05, -2.56863314e-06,  3.19799437e-05,\n",
            "        1.06643165e-05,  5.39180292e-06,  1.45197148e-04, -2.58096188e-05,\n",
            "        3.43016254e-05, -2.44127023e-06, -4.82140422e-06,  2.76302490e-05,\n",
            "        4.18147829e-05, -5.92461365e-05, -5.08992816e-05,  2.35844964e-05,\n",
            "       -9.96736344e-05, -3.18120656e-05,  1.93916894e-05, -1.36207436e-05,\n",
            "       -1.09720844e-04,  2.26376287e-05, -3.20526815e-05,  4.62614807e-05,\n",
            "       -3.91273570e-05,  6.83278631e-05, -2.69344600e-05,  1.29426462e-05,\n",
            "        4.45397818e-05,  4.00882236e-05,  1.50735228e-04, -6.94627442e-06,\n",
            "       -7.42085331e-06, -1.26589133e-04,  8.74598481e-06, -4.91030369e-05,\n",
            "       -2.86317709e-06, -3.95702009e-05,  6.93212314e-07, -1.19005512e-04,\n",
            "        1.66637583e-05,  1.08907712e-04, -5.93035911e-05,  1.16087394e-05,\n",
            "       -3.25951623e-06,  6.74439361e-05, -1.62352553e-05, -2.33259780e-05,\n",
            "        4.23167803e-05, -1.63912300e-05, -3.35033656e-06, -1.11063182e-05,\n",
            "       -1.88471204e-05, -7.04867398e-06,  3.05765279e-05,  6.71162252e-06,\n",
            "        7.34324203e-07, -1.26817540e-05, -1.09009652e-05, -2.84056936e-04,\n",
            "       -3.20133731e-05,  3.55664088e-05, -9.80709319e-06, -2.64919072e-05,\n",
            "        4.02314035e-05, -2.96542967e-05,  7.55525689e-05,  6.79875593e-05,\n",
            "        3.33760509e-05,  6.54234318e-05, -1.08771892e-05,  4.60484007e-05,\n",
            "       -4.25928883e-05,  5.63377471e-05,  6.10910502e-05,  5.68842370e-05,\n",
            "        4.41847897e-06,  4.89973099e-05, -1.92215211e-05,  9.15167620e-05,\n",
            "       -2.07765624e-02,  4.98996228e-02, -1.26912091e-02,  2.87151746e-02,\n",
            "       -7.93767045e-04, -7.85213988e-03,  1.46649070e-02,  2.31537782e-02,\n",
            "       -7.29661807e-03,  3.29049863e-02, -4.40547429e-02, -2.34684208e-04,\n",
            "        1.58654321e-02, -3.54940295e-02, -4.87919226e-02, -6.07662126e-02,\n",
            "        1.00757065e-03,  4.34676968e-02, -3.75340134e-02,  4.41115815e-03,\n",
            "       -4.00618929e-03,  1.66115491e-03, -7.14757945e-03, -1.25880232e-02,\n",
            "       -2.02975026e-03, -1.29567422e-02,  2.60086320e-02,  1.27990413e-02,\n",
            "        3.35760042e-02, -1.84595864e-02, -5.17648682e-02,  3.98050360e-02,\n",
            "       -1.89828053e-02,  1.24331750e-02,  2.70886812e-02,  2.29221061e-02,\n",
            "        3.03074569e-02, -6.87443316e-02,  3.29637080e-02,  7.03162421e-03,\n",
            "        1.19887907e-02, -1.22930249e-02,  1.80978775e-02, -5.92372753e-03,\n",
            "       -3.37447934e-02,  3.32455002e-02,  2.63072588e-02,  2.23609507e-02,\n",
            "        4.75340616e-03,  1.02051571e-02,  1.47304870e-03, -1.60647761e-02,\n",
            "        2.61133723e-02,  4.90564015e-03, -6.64554536e-02, -4.17497428e-03,\n",
            "        7.57042691e-03,  3.24824220e-03, -1.56707205e-02, -1.70071926e-02,\n",
            "        4.96435426e-02,  6.49784803e-02,  1.55799473e-02,  1.45738143e-02,\n",
            "       -4.69191857e-02,  8.21213797e-03,  2.22166888e-02, -1.35300378e-03,\n",
            "       -1.98921189e-02, -1.73597224e-02, -2.80012190e-02,  2.23692320e-02,\n",
            "       -7.00626709e-03,  3.02669890e-02, -3.14767510e-02,  1.62856672e-02,\n",
            "        4.54295650e-02,  2.15380602e-02,  3.39838080e-02, -8.57385062e-03,\n",
            "       -1.84231177e-02, -6.68350905e-02,  1.81765761e-03,  4.33570519e-02,\n",
            "       -1.12181306e-02, -1.22751947e-02, -3.47280987e-02, -5.55568375e-02,\n",
            "       -1.29791079e-02, -2.66161729e-02,  3.47862504e-02, -3.94587480e-02,\n",
            "        2.41842903e-02, -1.40850656e-02, -2.31467672e-02, -2.18597036e-02,\n",
            "        1.75910108e-02,  8.76921602e-03,  1.45957656e-02,  1.38528887e-02,\n",
            "        2.52583548e-02, -7.65039492e-03,  2.33212169e-02, -4.29529324e-03,\n",
            "       -1.24067478e-02,  1.07951090e-03,  3.05119250e-03, -1.06887348e-01,\n",
            "        3.20316255e-02,  3.74498032e-03,  1.67593602e-02, -2.85450667e-02,\n",
            "       -4.31742221e-02, -2.68619088e-03, -3.67735848e-02, -1.56353675e-02,\n",
            "       -4.45627794e-02,  2.26773620e-02, -5.78468777e-02, -6.08945731e-03,\n",
            "        7.58840591e-02, -2.79205181e-02,  6.49107769e-02, -3.14756855e-02,\n",
            "       -1.25468243e-02, -1.22008314e-02, -7.41638150e-03, -2.96647213e-02,\n",
            "       -1.07164487e-05,  5.37608685e-07,  2.63461006e-05,  1.29659538e-05,\n",
            "       -1.61580783e-06, -1.27042140e-05,  1.34657112e-05, -7.13479312e-05,\n",
            "        5.58409920e-06, -2.83884383e-05,  5.10398677e-05, -7.46639671e-06,\n",
            "        2.33905703e-05,  2.00403929e-06,  1.87631704e-05,  7.49158644e-05,\n",
            "       -1.18063799e-05, -9.14529664e-05, -2.06697987e-05,  2.81635894e-05,\n",
            "       -8.32750811e-06,  3.19661285e-06,  4.88050100e-05, -9.27445944e-06,\n",
            "       -3.05911017e-05,  3.65320484e-05,  4.97296605e-06,  3.88422050e-05,\n",
            "       -2.46065574e-05, -6.66565029e-06, -4.99148882e-07, -1.14406776e-05,\n",
            "       -3.28604547e-05, -5.91725620e-06,  7.77649620e-06,  2.61318764e-05,\n",
            "       -2.27054102e-06, -5.83411675e-05, -3.37996171e-05,  3.28609567e-05,\n",
            "        4.84044431e-05,  1.39962058e-05,  1.16823494e-05, -3.22188571e-05,\n",
            "        5.80956839e-05,  2.62637332e-05,  2.68199419e-05,  5.33435050e-05,\n",
            "        1.32371479e-05,  2.23208153e-05, -1.01006353e-05,  5.96704449e-05,\n",
            "       -2.42326450e-06, -9.42675797e-07,  1.09757981e-04, -2.66620045e-05,\n",
            "        2.02542687e-05, -1.06189964e-05, -1.99403621e-06,  1.21291550e-05,\n",
            "        5.73368379e-05, -6.37793273e-05, -5.31224505e-05, -5.14176099e-06,\n",
            "       -6.24621389e-05, -1.96469300e-05,  4.12014106e-06, -2.03387463e-05,\n",
            "       -7.26597063e-05,  4.89208560e-06, -3.58462603e-05,  2.94681122e-05,\n",
            "       -4.30560722e-05,  3.56106830e-05,  2.75530510e-07,  2.70419714e-05,\n",
            "        3.50138362e-05,  3.45408916e-05,  1.07602013e-04,  5.21337597e-06,\n",
            "       -1.40439997e-05, -9.87802196e-05,  4.04065941e-06, -4.50984226e-05,\n",
            "       -7.57341513e-06, -3.90326641e-05, -2.30839510e-06, -9.31935792e-05,\n",
            "        2.81524262e-05,  7.90417325e-05, -1.22245519e-05,  4.48259743e-06,\n",
            "        2.96614198e-05,  4.01701291e-05, -3.12984703e-05, -1.52533621e-05,\n",
            "        5.43145652e-05, -3.20995241e-05,  7.90911508e-06, -1.43034922e-05,\n",
            "       -9.68363929e-06, -8.37118205e-06,  1.45591075e-05, -7.37280106e-06,\n",
            "        2.93383546e-05,  8.69979704e-06,  7.01782301e-06, -1.97794652e-04,\n",
            "       -1.07280275e-05,  2.52279751e-05, -4.56697808e-06, -2.09828650e-05,\n",
            "        2.97747138e-05, -2.22287927e-05,  8.56728584e-05,  4.99792404e-05,\n",
            "        1.68544593e-05,  3.34730212e-05, -1.29755044e-05,  1.89775546e-05,\n",
            "       -2.64252958e-05,  3.68055807e-05,  5.26418880e-05,  3.71029964e-05,\n",
            "        6.77034086e-06,  5.36450534e-05, -3.43185202e-05,  7.47578233e-05],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(128, 10000), dtype=float32, numpy=\n",
            "array([[ 8.9119643e-04,  2.3487408e-04, -1.8597799e-04, ...,\n",
            "        -3.1616025e-07, -3.1675063e-07, -3.1735840e-07],\n",
            "       [-5.6276331e-04, -2.6218913e-06,  5.7762885e-04, ...,\n",
            "         1.7181039e-06,  1.7172217e-06,  1.7154308e-06],\n",
            "       [-1.1512151e-03, -1.2678779e-03, -6.6882058e-04, ...,\n",
            "         3.4588759e-06,  3.4575717e-06,  3.4554485e-06],\n",
            "       ...,\n",
            "       [ 1.7065274e-03,  3.2510498e-04,  2.1365222e-03, ...,\n",
            "        -3.5130390e-06, -3.5127434e-06, -3.5118542e-06],\n",
            "       [ 1.2237534e-03, -8.1436557e-04, -8.1778935e-04, ...,\n",
            "        -8.3723897e-08, -8.4008349e-08, -8.4112855e-08],\n",
            "       [ 2.1133202e-03,  3.3694461e-03,  2.7210282e-03, ...,\n",
            "        -4.5576926e-06, -4.5593297e-06, -4.5577290e-06]], dtype=float32)>, <tf.Tensor: shape=(10000,), dtype=float32, numpy=\n",
            "array([-0.7979983 , -1.0313321 , -1.0313317 , ...,  0.00200088,\n",
            "        0.00200036,  0.00200009], dtype=float32)>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "now, we have a list of tensors, t-list. We can use it to find clipped tensors. <b>clip_by_global_norm</b> clips values of multiple tensors by the ratio of the sum of their norms.\n",
        "\n",
        "<b>clip_by_global_norm</b> get <i>t-list</i> as input and returns 2 things:\n",
        "\n",
        "<ul>\n",
        "    <li>a list of clipped tensors, so called <i>list_clipped</i></li>\n",
        "    <li>the global norm (global_norm) of all tensors in t_list</li>\n",
        "</ul>\n"
      ],
      "metadata": {
        "id": "SwBSbHZzhZev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the gradient clipping threshold\n",
        "grads, _ = tf.clip_by_global_norm(grad_t_list, max_grad_norm)\n",
        "grads"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDeGwWfLhanV",
        "outputId": "49acc174-31dc-4982-afc4-3afc17b2fa5b"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tensorflow.python.framework.indexed_slices.IndexedSlices at 0x78289d2ed150>,\n",
              " <tf.Tensor: shape=(200, 1024), dtype=float32, numpy=\n",
              " array([[-6.6341090e-07, -1.7943911e-06,  1.2738228e-06, ...,\n",
              "          1.4700987e-06, -1.9430928e-09,  1.8701965e-07],\n",
              "        [-1.1954504e-07, -8.6421505e-07,  2.6428540e-07, ...,\n",
              "          2.5293861e-07,  1.8830329e-07, -6.4357785e-08],\n",
              "        [-9.1166379e-07, -1.0903372e-06, -1.3817676e-06, ...,\n",
              "          8.6296490e-07,  2.2890774e-07, -2.4464435e-07],\n",
              "        ...,\n",
              "        [ 9.2097594e-08, -2.2139028e-07,  5.9687051e-07, ...,\n",
              "         -4.1208261e-07, -8.1399963e-07,  3.2546933e-07],\n",
              "        [ 5.7409784e-07,  3.2205017e-07,  8.2884753e-07, ...,\n",
              "          3.1615627e-07, -1.4287221e-07,  5.7324735e-07],\n",
              "        [ 2.3974297e-07,  1.8661331e-07, -1.1566767e-06, ...,\n",
              "          3.6195331e-08, -2.9375056e-07, -1.0501839e-07]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(256, 1024), dtype=float32, numpy=\n",
              " array([[ 2.48230947e-07,  6.90864255e-08, -3.91676167e-08, ...,\n",
              "         -5.76186324e-07,  3.17301208e-08, -3.51071314e-08],\n",
              "        [ 1.39880029e-07, -2.06876166e-07, -3.01223508e-08, ...,\n",
              "          2.30878570e-07,  4.72560870e-08, -1.03256994e-07],\n",
              "        [-1.25245485e-08, -1.11857688e-07, -2.05892377e-07, ...,\n",
              "          7.96272161e-07,  5.08743057e-08, -1.45689910e-07],\n",
              "        ...,\n",
              "        [-1.37991947e-07, -5.00081541e-08, -1.79421875e-07, ...,\n",
              "          1.53559097e-06, -6.20987493e-08, -1.70686334e-07],\n",
              "        [-4.87362648e-08,  6.67419897e-08,  7.52084617e-10, ...,\n",
              "         -6.77902221e-07, -2.09715623e-07,  8.91903262e-09],\n",
              "        [ 1.45648613e-08, -4.49105642e-10,  3.01994987e-07, ...,\n",
              "         -4.03727313e-07, -8.51402007e-08,  1.74455010e-07]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1024,), dtype=float32, numpy=\n",
              " array([-1.97362642e-05,  1.38577525e-06, -1.39434505e-05, ...,\n",
              "         1.09518514e-04,  1.70518160e-06, -1.31859051e-05], dtype=float32)>,\n",
              " <tf.Tensor: shape=(256, 512), dtype=float32, numpy=\n",
              " array([[ 1.0003672e-07, -1.8315536e-07,  9.2712277e-08, ...,\n",
              "         -2.3051783e-07,  2.8799468e-07, -3.0240651e-07],\n",
              "        [-1.3492632e-07, -3.7076217e-07,  7.6814004e-08, ...,\n",
              "         -3.7342772e-08, -3.5162671e-08,  1.7742528e-07],\n",
              "        [-3.4354684e-08, -9.7082015e-08, -9.1791623e-09, ...,\n",
              "         -6.5315874e-07, -2.0342924e-07,  3.7967646e-07],\n",
              "        ...,\n",
              "        [-1.1480187e-07,  2.6787731e-08,  1.5360928e-07, ...,\n",
              "         -2.3742673e-07, -4.4051237e-08,  3.0338629e-07],\n",
              "        [ 1.2744434e-07, -6.2218035e-09, -1.5077834e-08, ...,\n",
              "         -4.8772677e-07,  2.7561015e-07, -3.9644561e-07],\n",
              "        [-6.4335275e-09,  8.9673684e-08, -7.4075146e-08, ...,\n",
              "         -3.8872986e-07,  1.2266572e-07, -3.2854462e-07]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(128, 512), dtype=float32, numpy=\n",
              " array([[-2.45507465e-07, -2.34891218e-08,  1.34933131e-08, ...,\n",
              "          1.25672670e-07,  8.60563265e-09,  2.69166041e-08],\n",
              "        [ 9.36552524e-08,  3.36090750e-07, -3.06653085e-08, ...,\n",
              "         -2.07855742e-08,  1.98790602e-08,  9.77043442e-08],\n",
              "        [-1.29785590e-07,  7.31448964e-08, -1.44647458e-07, ...,\n",
              "          2.07128437e-07,  4.85118115e-08,  1.73954518e-07],\n",
              "        ...,\n",
              "        [-1.63965396e-07, -3.78249254e-08,  2.93489592e-07, ...,\n",
              "         -4.99750627e-07, -1.72583743e-08, -1.19292281e-07],\n",
              "        [ 2.22653256e-08, -1.38404303e-07,  3.87632255e-08, ...,\n",
              "          5.20002104e-08, -3.00967429e-08,  7.84287568e-09],\n",
              "        [ 2.38956517e-08,  8.92155185e-08, -2.95615834e-08, ...,\n",
              "          9.89713911e-08,  1.04824316e-07, -4.42154885e-07]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(512,), dtype=float32, numpy=\n",
              " array([-8.27287204e-06,  2.42986789e-06,  2.99144212e-05,  9.77059972e-06,\n",
              "        -6.61772106e-07, -4.89284639e-06,  7.43267356e-06, -4.98777299e-05,\n",
              "         3.44762748e-06, -2.67436881e-05,  4.39580690e-05, -2.41312409e-06,\n",
              "         1.49732705e-05,  8.39675704e-06,  1.58637467e-05,  6.83307589e-05,\n",
              "        -1.09334887e-05, -7.52532796e-05, -2.75037964e-05,  2.46473501e-05,\n",
              "        -7.01034151e-06,  8.89881812e-06,  4.40342737e-05,  1.17747823e-06,\n",
              "        -2.61652658e-05,  3.69978006e-05,  4.74753688e-06,  3.81383543e-05,\n",
              "        -1.89488455e-05, -2.78850484e-06, -3.79353878e-06,  9.39883648e-06,\n",
              "        -3.55833254e-05, -1.15260696e-06, -4.19075423e-06,  2.27818637e-05,\n",
              "        -2.51799520e-06, -5.08688172e-05, -2.12781124e-05,  3.18023085e-05,\n",
              "         4.85332421e-05,  1.17219197e-05,  1.40593656e-05, -2.82514848e-05,\n",
              "         4.71851854e-05,  2.32980055e-05,  2.64546270e-05,  4.63524702e-05,\n",
              "         7.16754403e-06,  1.52473749e-05, -3.87958153e-06,  4.85630226e-05,\n",
              "         3.16046680e-07, -1.92421794e-06,  9.70056280e-05, -2.24246596e-05,\n",
              "         1.87356054e-05, -3.59596379e-06, -3.73113949e-06,  8.29334112e-06,\n",
              "         5.94078338e-05, -5.82126959e-05, -4.89686427e-05, -6.26651854e-06,\n",
              "        -6.24077875e-05, -1.95451612e-05, -1.75345394e-06, -2.52567443e-05,\n",
              "        -7.19027739e-05,  2.57731131e-06, -3.48911854e-05,  2.77004074e-05,\n",
              "        -4.53034882e-05,  2.64862210e-05,  8.02370596e-06,  2.14215343e-05,\n",
              "         2.42730057e-05,  3.12372285e-05,  9.81087433e-05, -7.15221177e-07,\n",
              "        -1.50061769e-05, -8.18678454e-05,  1.86900452e-05, -4.04879320e-05,\n",
              "        -3.37007555e-06, -3.18693164e-05,  3.45997978e-06, -8.67399358e-05,\n",
              "         2.90240296e-05,  7.86883247e-05, -1.32372215e-05,  3.44234468e-06,\n",
              "         2.31873146e-05,  3.26161098e-05, -2.72523630e-05, -5.37690630e-06,\n",
              "         5.04463642e-05, -3.00664906e-05,  1.35263781e-05, -1.84616492e-05,\n",
              "        -1.43503112e-05, -7.57593398e-06,  1.46552320e-05, -9.82609981e-06,\n",
              "         1.46076845e-05,  1.01433288e-05,  1.31565012e-05, -1.69745588e-04,\n",
              "        -1.30933313e-05,  2.39807596e-05, -3.50999971e-06, -1.81861269e-05,\n",
              "         2.91861215e-05, -1.37549641e-05,  6.90855813e-05,  5.58792381e-05,\n",
              "         1.93699943e-05,  3.30529183e-05, -1.36619783e-05,  2.20918173e-05,\n",
              "        -3.07503251e-05,  3.47082678e-05,  5.19444075e-05,  2.91172964e-05,\n",
              "         9.19579543e-06,  5.05988392e-05, -3.27931266e-05,  6.19021739e-05,\n",
              "        -6.56905922e-06, -2.58390774e-05,  1.25876577e-05,  2.71560057e-05,\n",
              "         4.82432461e-06, -3.14191821e-05,  2.06333734e-05, -8.90538067e-05,\n",
              "         1.26681189e-05, -7.78348112e-06,  5.55052975e-05, -2.22825429e-06,\n",
              "         2.09288755e-05, -1.00098168e-05,  1.89091588e-05,  7.40004616e-05,\n",
              "         1.79134076e-06, -8.90458759e-05,  1.37164534e-06,  2.31195972e-05,\n",
              "         1.10742176e-05,  1.40395323e-05,  4.88866026e-05, -1.31521065e-05,\n",
              "        -4.83218173e-05,  3.99566707e-05, -1.14668137e-05,  5.84517729e-05,\n",
              "        -3.17670037e-06,  8.66497703e-06, -3.21629923e-05, -9.46541149e-06,\n",
              "        -3.45106164e-05, -3.02835779e-05,  3.80030979e-05,  3.31493939e-05,\n",
              "        -1.53465680e-05, -3.36683661e-05, -2.55684008e-05,  3.42316998e-05,\n",
              "         3.55028169e-05,  1.36976578e-05,  1.20525674e-05, -3.13451019e-05,\n",
              "         6.95993222e-05,  4.45724654e-05,  5.00133829e-05,  3.98605916e-05,\n",
              "        -5.97468897e-07, -1.09309321e-05, -2.56863314e-06,  3.19799437e-05,\n",
              "         1.06643165e-05,  5.39180292e-06,  1.45197148e-04, -2.58096188e-05,\n",
              "         3.43016254e-05, -2.44127023e-06, -4.82140422e-06,  2.76302490e-05,\n",
              "         4.18147829e-05, -5.92461365e-05, -5.08992816e-05,  2.35844964e-05,\n",
              "        -9.96736344e-05, -3.18120656e-05,  1.93916894e-05, -1.36207436e-05,\n",
              "        -1.09720844e-04,  2.26376287e-05, -3.20526815e-05,  4.62614807e-05,\n",
              "        -3.91273570e-05,  6.83278631e-05, -2.69344600e-05,  1.29426462e-05,\n",
              "         4.45397818e-05,  4.00882236e-05,  1.50735228e-04, -6.94627442e-06,\n",
              "        -7.42085331e-06, -1.26589133e-04,  8.74598481e-06, -4.91030369e-05,\n",
              "        -2.86317709e-06, -3.95702009e-05,  6.93212314e-07, -1.19005512e-04,\n",
              "         1.66637583e-05,  1.08907712e-04, -5.93035911e-05,  1.16087394e-05,\n",
              "        -3.25951623e-06,  6.74439361e-05, -1.62352553e-05, -2.33259780e-05,\n",
              "         4.23167803e-05, -1.63912300e-05, -3.35033656e-06, -1.11063182e-05,\n",
              "        -1.88471204e-05, -7.04867398e-06,  3.05765279e-05,  6.71162252e-06,\n",
              "         7.34324203e-07, -1.26817540e-05, -1.09009652e-05, -2.84056936e-04,\n",
              "        -3.20133731e-05,  3.55664088e-05, -9.80709319e-06, -2.64919072e-05,\n",
              "         4.02314035e-05, -2.96542967e-05,  7.55525689e-05,  6.79875593e-05,\n",
              "         3.33760509e-05,  6.54234318e-05, -1.08771892e-05,  4.60484007e-05,\n",
              "        -4.25928883e-05,  5.63377471e-05,  6.10910502e-05,  5.68842370e-05,\n",
              "         4.41847897e-06,  4.89973099e-05, -1.92215211e-05,  9.15167620e-05,\n",
              "        -2.07765624e-02,  4.98996228e-02, -1.26912091e-02,  2.87151746e-02,\n",
              "        -7.93767045e-04, -7.85213988e-03,  1.46649070e-02,  2.31537782e-02,\n",
              "        -7.29661807e-03,  3.29049863e-02, -4.40547429e-02, -2.34684208e-04,\n",
              "         1.58654321e-02, -3.54940295e-02, -4.87919226e-02, -6.07662126e-02,\n",
              "         1.00757065e-03,  4.34676968e-02, -3.75340134e-02,  4.41115815e-03,\n",
              "        -4.00618929e-03,  1.66115491e-03, -7.14757945e-03, -1.25880232e-02,\n",
              "        -2.02975026e-03, -1.29567422e-02,  2.60086320e-02,  1.27990413e-02,\n",
              "         3.35760042e-02, -1.84595864e-02, -5.17648682e-02,  3.98050360e-02,\n",
              "        -1.89828053e-02,  1.24331750e-02,  2.70886812e-02,  2.29221061e-02,\n",
              "         3.03074569e-02, -6.87443316e-02,  3.29637080e-02,  7.03162421e-03,\n",
              "         1.19887907e-02, -1.22930249e-02,  1.80978775e-02, -5.92372753e-03,\n",
              "        -3.37447934e-02,  3.32455002e-02,  2.63072588e-02,  2.23609507e-02,\n",
              "         4.75340616e-03,  1.02051571e-02,  1.47304870e-03, -1.60647761e-02,\n",
              "         2.61133723e-02,  4.90564015e-03, -6.64554536e-02, -4.17497428e-03,\n",
              "         7.57042691e-03,  3.24824220e-03, -1.56707205e-02, -1.70071926e-02,\n",
              "         4.96435426e-02,  6.49784803e-02,  1.55799473e-02,  1.45738143e-02,\n",
              "        -4.69191857e-02,  8.21213797e-03,  2.22166888e-02, -1.35300378e-03,\n",
              "        -1.98921189e-02, -1.73597224e-02, -2.80012190e-02,  2.23692320e-02,\n",
              "        -7.00626709e-03,  3.02669890e-02, -3.14767510e-02,  1.62856672e-02,\n",
              "         4.54295650e-02,  2.15380602e-02,  3.39838080e-02, -8.57385062e-03,\n",
              "        -1.84231177e-02, -6.68350905e-02,  1.81765761e-03,  4.33570519e-02,\n",
              "        -1.12181306e-02, -1.22751947e-02, -3.47280987e-02, -5.55568375e-02,\n",
              "        -1.29791079e-02, -2.66161729e-02,  3.47862504e-02, -3.94587480e-02,\n",
              "         2.41842903e-02, -1.40850656e-02, -2.31467672e-02, -2.18597036e-02,\n",
              "         1.75910108e-02,  8.76921602e-03,  1.45957656e-02,  1.38528887e-02,\n",
              "         2.52583548e-02, -7.65039492e-03,  2.33212169e-02, -4.29529324e-03,\n",
              "        -1.24067478e-02,  1.07951090e-03,  3.05119250e-03, -1.06887348e-01,\n",
              "         3.20316255e-02,  3.74498032e-03,  1.67593602e-02, -2.85450667e-02,\n",
              "        -4.31742221e-02, -2.68619088e-03, -3.67735848e-02, -1.56353675e-02,\n",
              "        -4.45627794e-02,  2.26773620e-02, -5.78468777e-02, -6.08945731e-03,\n",
              "         7.58840591e-02, -2.79205181e-02,  6.49107769e-02, -3.14756855e-02,\n",
              "        -1.25468243e-02, -1.22008314e-02, -7.41638150e-03, -2.96647213e-02,\n",
              "        -1.07164487e-05,  5.37608685e-07,  2.63461006e-05,  1.29659538e-05,\n",
              "        -1.61580783e-06, -1.27042140e-05,  1.34657112e-05, -7.13479312e-05,\n",
              "         5.58409920e-06, -2.83884383e-05,  5.10398677e-05, -7.46639671e-06,\n",
              "         2.33905703e-05,  2.00403929e-06,  1.87631704e-05,  7.49158644e-05,\n",
              "        -1.18063799e-05, -9.14529664e-05, -2.06697987e-05,  2.81635894e-05,\n",
              "        -8.32750811e-06,  3.19661285e-06,  4.88050100e-05, -9.27445944e-06,\n",
              "        -3.05911017e-05,  3.65320484e-05,  4.97296605e-06,  3.88422050e-05,\n",
              "        -2.46065574e-05, -6.66565029e-06, -4.99148882e-07, -1.14406776e-05,\n",
              "        -3.28604547e-05, -5.91725620e-06,  7.77649620e-06,  2.61318764e-05,\n",
              "        -2.27054102e-06, -5.83411675e-05, -3.37996171e-05,  3.28609567e-05,\n",
              "         4.84044431e-05,  1.39962058e-05,  1.16823494e-05, -3.22188571e-05,\n",
              "         5.80956839e-05,  2.62637332e-05,  2.68199419e-05,  5.33435050e-05,\n",
              "         1.32371479e-05,  2.23208153e-05, -1.01006353e-05,  5.96704449e-05,\n",
              "        -2.42326450e-06, -9.42675797e-07,  1.09757981e-04, -2.66620045e-05,\n",
              "         2.02542687e-05, -1.06189964e-05, -1.99403621e-06,  1.21291550e-05,\n",
              "         5.73368379e-05, -6.37793273e-05, -5.31224505e-05, -5.14176099e-06,\n",
              "        -6.24621389e-05, -1.96469300e-05,  4.12014106e-06, -2.03387463e-05,\n",
              "        -7.26597063e-05,  4.89208560e-06, -3.58462603e-05,  2.94681122e-05,\n",
              "        -4.30560722e-05,  3.56106830e-05,  2.75530510e-07,  2.70419714e-05,\n",
              "         3.50138362e-05,  3.45408916e-05,  1.07602013e-04,  5.21337597e-06,\n",
              "        -1.40439997e-05, -9.87802196e-05,  4.04065941e-06, -4.50984226e-05,\n",
              "        -7.57341513e-06, -3.90326641e-05, -2.30839510e-06, -9.31935792e-05,\n",
              "         2.81524262e-05,  7.90417325e-05, -1.22245519e-05,  4.48259743e-06,\n",
              "         2.96614198e-05,  4.01701291e-05, -3.12984703e-05, -1.52533621e-05,\n",
              "         5.43145652e-05, -3.20995241e-05,  7.90911508e-06, -1.43034922e-05,\n",
              "        -9.68363929e-06, -8.37118205e-06,  1.45591075e-05, -7.37280106e-06,\n",
              "         2.93383546e-05,  8.69979704e-06,  7.01782301e-06, -1.97794652e-04,\n",
              "        -1.07280275e-05,  2.52279751e-05, -4.56697808e-06, -2.09828650e-05,\n",
              "         2.97747138e-05, -2.22287927e-05,  8.56728584e-05,  4.99792404e-05,\n",
              "         1.68544593e-05,  3.34730212e-05, -1.29755044e-05,  1.89775546e-05,\n",
              "        -2.64252958e-05,  3.68055807e-05,  5.26418880e-05,  3.71029964e-05,\n",
              "         6.77034086e-06,  5.36450534e-05, -3.43185202e-05,  7.47578233e-05],\n",
              "       dtype=float32)>,\n",
              " <tf.Tensor: shape=(128, 10000), dtype=float32, numpy=\n",
              " array([[ 8.9119643e-04,  2.3487408e-04, -1.8597799e-04, ...,\n",
              "         -3.1616025e-07, -3.1675063e-07, -3.1735840e-07],\n",
              "        [-5.6276331e-04, -2.6218913e-06,  5.7762885e-04, ...,\n",
              "          1.7181039e-06,  1.7172217e-06,  1.7154308e-06],\n",
              "        [-1.1512151e-03, -1.2678779e-03, -6.6882058e-04, ...,\n",
              "          3.4588759e-06,  3.4575717e-06,  3.4554485e-06],\n",
              "        ...,\n",
              "        [ 1.7065274e-03,  3.2510498e-04,  2.1365222e-03, ...,\n",
              "         -3.5130390e-06, -3.5127434e-06, -3.5118542e-06],\n",
              "        [ 1.2237534e-03, -8.1436557e-04, -8.1778935e-04, ...,\n",
              "         -8.3723897e-08, -8.4008349e-08, -8.4112855e-08],\n",
              "        [ 2.1133202e-03,  3.3694461e-03,  2.7210282e-03, ...,\n",
              "         -4.5576926e-06, -4.5593297e-06, -4.5577290e-06]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(10000,), dtype=float32, numpy=\n",
              " array([-0.7979983 , -1.0313321 , -1.0313317 , ...,  0.00200088,\n",
              "         0.00200036,  0.00200009], dtype=float32)>]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4> 4.Apply the optimizer to the variables/gradients tuple. </h4>\n"
      ],
      "metadata": {
        "id": "6u014Wu2hdSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the training TensorFlow Operation through our optimizer\n",
        "train_op = optimizer.apply_gradients(zip(grads, tvars))"
      ],
      "metadata": {
        "id": "PSDL249bhdu8"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O lyrics.csv https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XP39UmulR33",
        "outputId": "b3601c50-3150-4d73-d32e-1978b4d0617f"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-16 09:33:53--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘lyrics.csv’\n",
            "\n",
            "\rlyrics.csv            0%[                    ]       0  --.-KB/s               \rlyrics.csv          100%[===================>]   1.06M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2025-07-16 09:33:53 (17.3 MB/s) - ‘lyrics.csv’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ]
    }
  ]
}